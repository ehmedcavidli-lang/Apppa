using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;

class IntelligentAgent
{
    // Strategiyalar (fÉ™rqli qÉ™rar nÃ¶vlÉ™ri)
    static string[] strategies = { "Riskli", "TÉ™hlÃ¼kÉ™siz", "Orta" };
    static Random random = new Random();

    // StrategiyalarÄ±n nÉ™ticÉ™ tarixÃ§É™si
    static Dictionary<string, List<double>> rewardHistory = new Dictionary<string, List<double>>()
    {
        { "Riskli", new List<double>() },
        { "TÉ™hlÃ¼kÉ™siz", new List<double>() },
        { "Orta", new List<double>() }
    };

    static double explorationRate = 0.2; // tÉ™sadÃ¼fi yeni strategiya sÄ±naq ehtimalÄ±
    static int totalDays = 100;
    static double learningRate = 0.1;

    static void Main()
    {
        Console.WriteLine("ğŸ§  Ä°nsan QÉ™rar Ã–yrÉ™nmÉ™ SimulyasiyasÄ± (Feedback Loop + Reinforcement)\n");

        string currentStrategy = strategies[random.Next(strategies.Length)];

        for (int day = 1; day <= totalDays; day++)
        {
            // --- 1. StrategiyanÄ± seÃ§ (bÉ™zÉ™n yeni strategiya sÄ±naqdan keÃ§sin)
            if (random.NextDouble() < explorationRate)
                currentStrategy = strategies[random.Next(strategies.Length)];
            else
                currentStrategy = SelectBestStrategy();

            // --- 2. StrategiyanÄ±n nÉ™ticÉ™sini simulyasiya et
            double reward = GetReward(currentStrategy);

            // --- 3. TarixÃ§É™yÉ™ É™lavÉ™ et
            rewardHistory[currentStrategy].Add(reward);

            // --- 4. TÉ™dris (Ã¶yrÉ™nmÉ™) - keÃ§miÅŸ nÉ™ticÉ™lÉ™rÉ™ É™sasÉ™n exploration-u azaldÄ±rÄ±q
            explorationRate *= 0.99; // zamanla agent daha sabit qÉ™rarlar verir

            // --- 5. Vizual Ã§Ä±xÄ±ÅŸ
            Console.WriteLine($"GÃ¼n {day:00}: Strategiya = {currentStrategy,-10} | NÉ™ticÉ™ (mÃ¼kafat) = {reward,5:F2} | " +
                              $"Orta MÃ¼kafat = {rewardHistory[currentStrategy].Average(),5:F2}");

            Thread.Sleep(50);
        }

        Console.WriteLine("\nğŸ“Š Simulyasiya bitdi. Statistik nÉ™ticÉ™lÉ™r:\n");
        foreach (var s in strategies)
        {
            var avg = rewardHistory[s].Count > 0 ? rewardHistory[s].Average() : 0;
            Console.WriteLine($"{s,-10} â†’ Orta mÃ¼kafat: {avg:F2}, CÉ™mi: {rewardHistory[s].Count} dÉ™fÉ™ seÃ§ilib.");
        }

        Console.WriteLine("\nâœ… Agent É™n Ã§ox istifadÉ™ etdiyi strategiyanÄ± 'optimal davranÄ±ÅŸ' kimi Ã¶yrÉ™nmiÅŸ olur.");
    }

    // StrategiyanÄ±n nÉ™ticÉ™sini modellÉ™ÅŸdiririk
    static double GetReward(string strategy)
    {
        switch (strategy)
        {
            case "Riskli":
                // YÃ¼ksÉ™k qazanc, amma risklidir
                return random.NextDouble() < 0.5 ? -2 : +4; // 50% uÄŸur, 50% cÉ™za
            case "TÉ™hlÃ¼kÉ™siz":
                // Daim az, amma sabit mÃ¼kafat
                return 1.0 + random.NextDouble() * 0.5; // 1â€“1.5 arasÄ±
            case "Orta":
                // BalanslÄ± seÃ§im
                return random.NextDouble() < 0.7 ? 2.0 : -1.0; // 70% uÄŸur
            default:
                return 0;
        }
    }

    // Æn yaxÅŸÄ± strategiyanÄ± tap (keÃ§miÅŸ mÃ¼kafatlarÄ±n ortalamasÄ±na É™sasÉ™n)
    static string SelectBestStrategy()
    {
        string best = strategies[0];
        double bestAvg = double.NegativeInfinity;

        foreach (var s in strategies)
        {
            if (rewardHistory[s].Count == 0) continue;
            double avg = rewardHistory[s].Average();
            if (avg > bestAvg)
            {
                bestAvg = avg;
                best = s;
            }
        }

        return best;
    }
}
